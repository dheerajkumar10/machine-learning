#!/usr/bin/env python
# coding: utf-8

# In[41]:


import numpy as np
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')


# In[42]:


dataset1 = [(( 1.6398767752769, 88.883711494291, 31), 'M' ),
(( 1.6793587237148, 78.251133790593, 33), 'M' ),
(( 1.5606515359382, 80.379998232509, 31), 'M' ),
(( 1.7041530344833, 79.042241386106, 32), 'W' ),
(( 1.7902744499504, 85.490626529836, 29), 'M' ),
(( 1.9114216491429, 88.583502900854, 32), 'M' ),
(( 1.663548694822, 79.334614233063, 40), 'W' ),
(( 1.617632971184, 75.775365798322, 31), 'M' ),
(( 1.7860510851332, 79.669328833931, 30), 'M' ),
(( 1.7471626838103, 91.554297596111, 37), 'M' ),
(( 1.6556706330438, 75.342441750817, 35), 'W' ),
(( 1.6286051561942, 82.313561191238, 35), 'W' ),
(( 1.9686795347355, 88.412367429298, 28), 'W' ),
(( 1.6536849541587, 81.876114419651, 37), 'M' ),
(( 1.7610802870024, 82.988874559137, 32), 'M' ),
(( 1.6532023744521, 75.112316142275, 36), 'W' ),
(( 1.6488888245147, 85.514239601957, 33), 'M' ),
(( 1.8999672054599, 88.901713931905, 28), 'M' ),
(( 1.966309884977, 85.960854309352, 34), 'W' ),
(( 1.7419989152201, 76.660687308549, 34), 'W' ),
(( 1.7410759420504, 88.45516564909, 28), 'W' ),
(( 1.6128717285128, 81.665533303814, 33), 'W' ),
(( 1.6564895965606, 75.620689385906, 37), 'W' ),
(( 1.7211014604543, 82.167763986892, 30), 'M' ),
(( 1.7561740337006, 83.307181550011, 33), 'M' ),
(( 1.829358792818, 79.556738736726, 31), 'M' ),
(( 1.6988479546535, 72.10698614958, 36), 'W' ),
(( 1.7001898133107, 77.667564587703, 30), 'W' ),
(( 1.8318014740353, 79.401723669333, 34), 'W' ),
(( 1.7099296818001, 79.91983280517, 33), 'M' ),
(( 1.7122213159364, 80.630692309157, 27), 'W' ),
(( 1.8055173032312, 82.277319781475, 35), 'W' ),
(( 1.7139583336454, 84.392207033842, 32), 'W' ),
(( 1.6497621909206, 86.700815495777, 32), 'W' ),
(( 1.7587413893208, 81.862466664499, 28), 'M' ),
(( 1.7920179991514, 83.054454585374, 29), 'M' ),
(( 1.7185356648902, 88.04269294477, 30), 'M' ),
(( 1.7299525968726, 84.863853163678, 32), 'W' ),
(( 1.7128072110792, 75.247967717682, 28), 'M' ),
(( 1.7090113354922, 81.975751013121, 38), 'M' ),
(( 1.6408347829316, 85.532149194174, 36), 'M' ),
(( 1.9439955398178, 91.884484957824, 28), 'W' ),
(( 1.7274177034241, 90.680829821807, 29), 'M' ),
(( 1.7431383422182, 79.396931399357, 29), 'M' ),
(( 1.7627304528441, 77.823612566684, 34), 'M' ),
(( 1.697511194971, 83.219306060898, 36), 'M' ),
(( 1.7144352542511, 74.447483201619, 30), 'W' ),
(( 1.9320520994348, 87.364788215837, 33), 'M' ),
(( 1.7848924060926, 90.275129770064, 36), 'M' ),
(( 1.8158317123786, 79.843909017857, 34), 'W' ),
(( 1.6504722768288, 79.584402934576, 31), 'W' ),
(( 1.7927896572691, 87.693456960208, 39), 'M' ),
(( 1.6788550699291, 75.452096416904, 30), 'W' ),
(( 1.6906902585759, 90.721382227158, 32), 'M' ),
(( 1.7969231045757, 81.175470577644, 32), 'W' ),
(( 1.8272198495309, 78.281776425164, 29), 'W' ),
(( 1.5780872658714, 73.663400417089, 34), 'W' ),
(( 1.8541763770393, 82.572365028261, 28), 'M' ),
(( 1.7572046635299, 80.51849073263, 35), 'M' ),
(( 1.7186152115652, 86.220888855088, 33), 'W' ),
(( 1.6641907978382, 79.210050597573, 26), 'W' ),
(( 1.5199771169132, 71.317841016816, 33), 'W' ),
(( 1.6250655934722, 74.407003024961, 32), 'W' ),
(( 1.8675473239669, 84.448244601362, 29), 'W' ),
(( 1.8404486486111, 89.426699375902, 29), 'W' ),
(( 1.8757743059545, 81.999002746239, 35), 'M' ),
(( 1.7632815092034, 79.36824086749, 35), 'M' ),
(( 1.8132125109131, 82.643741757309, 26), 'W' ),
(( 1.7547850607383, 84.541706225928, 32), 'W' ),
(( 1.7703652978655, 79.83725077508, 32), 'W' ),
(( 1.7580369855044, 86.597354438986, 26), 'M' ),
(( 1.7540620222022, 70.509003009041, 32), 'W' ),
(( 1.6943549127417, 79.566630883349, 28), 'M' ),
(( 1.7406163378013, 85.112612000104, 30), 'W' ),
(( 1.7363444470048, 88.908813091598, 34), 'M' ),
(( 1.7657736823754, 89.65008339188, 35), 'M' ),
(( 1.7000682489752, 82.319801914129, 31), 'M' ),
(( 1.8287655119064, 82.096196760201, 30), 'W' ),
(( 1.6012802654675, 78.36689506328, 32), 'W' ),
(( 1.5567397767717, 76.97634718814, 36), 'W' ),
(( 1.6359947298447, 74.084357364286, 43), 'W' ),
(( 1.8480482716516, 89.617957957534, 29), 'M' ),
(( 1.7950508480979, 85.134689958236, 32), 'M' ),
(( 1.7741176279525, 81.226426984581, 37), 'M' ),
(( 1.5184339504451, 75.479618720447, 35), 'W' ),
(( 1.8098540158159, 79.544455119207, 35), 'W' ),
(( 1.8775407864433, 95.542290746789, 38), 'M' ),
(( 1.666959379114, 77.424974269731, 32), 'M' ),
(( 1.8160944808652, 88.0756292322, 35), 'M' ),
(( 1.7852503682952, 80.025155244015, 36), 'W'),
(( 1.7997278803457, 84.730546785786, 29), 'M' ),
(( 1.8553132021196, 85.372906688875, 39), 'M' ),
(( 1.7402195975081, 80.755452542812, 36), 'M' ),
(( 1.6935735594697, 90.300889406346, 35), 'M' ),
(( 1.6479845599911, 82.279738450111, 32), 'M' ),
(( 1.7497769481617, 81.854049161695, 36), 'W' ),
(( 1.6131867795702, 79.679699684502, 28), 'W' ),
(( 1.6785597961667, 79.605139914867, 27), 'W' ),
(( 1.7990235331177, 81.326076437711, 35), 'W' ),
(( 1.8004516454367, 87.334640212661, 36), 'M' ),
(( 1.7752079108488, 75.374505132426, 33), 'W' ),
(( 1.7788378081896, 95.569026528677, 31), 'M' ),
(( 1.6332949719903, 67.084064485731, 39), 'W' ),
(( 1.7470876651889, 84.060086797003, 32), 'W' ),
(( 1.6903417883801, 88.157990527444, 36), 'M' ),
(( 1.5755320781775, 81.339292392716, 36), 'W' ),
(( 1.8613846838884, 80.617099812841, 34), 'W' ),
(( 1.7255361874771, 79.04831015098, 39), 'W' ),
(( 1.721946923349, 76.237725758393, 33), 'W' ),
(( 1.8764388000423, 87.201679825193, 33), 'M' ),
(( 1.8643130511338, 84.441050707272, 34), 'M' ),
(( 1.6795079349624, 77.485796908393, 33), 'W' ),
(( 1.7861997754645, 85.122321137222, 30), 'M' ),
(( 1.7835146320575, 80.885455045068, 31), 'M' ),
(( 1.7492347000938, 91.940494960301, 30), 'M' ),
(( 1.7346249569595, 80.461035920457, 34), 'M' ),
(( 1.7475710365745, 82.417748592106, 36), 'M' ),
(( 1.6369916904163, 63.694409193906, 34), 'W' ),
(( 1.7279105168181, 78.127793305004, 32), 'W' ),
(( 1.8962250581481, 85.784793130339, 32), 'W' )]

trainData = list(a[0] for a in dataset1)
#here we removed gender from the data given.
X=np.array(trainData)


# In[43]:


#reference is from 
#https://github.com/Darkprogrammerpb/DeepLearningProjects/blob/master/Project40/agglomerative_hierarchial_clustering/Hierarchial%20Agglomerative%20clustering.ipynb
# reffered this website and https://medium.com/@darkprogrammerpb/agglomerative-hierarchial-clustering-from-scratch-ec50e14c3826

class Distance(object):
    
    def __init__(self):
        pass
    
    def sampledist(self,s1,s2):
# took a reference from above given website for comparing type of variable
        if str(type(s2[0]))!='<class \'list\'>':
            s2=[s2]
        if str(type(s1[0]))!='<class \'list\'>':
            s1=[s1]
        m = len(s1)
        n = len(s2)
        dist = []
        if n>=m:
            for i in range(n):
                for j in range(m):
                    if (len(s2[i])>=len(s1[j])) and str(type(s2[i][0])!='<class \'list\'>'):
                        dist.append(self.clusterdist(s2[i],s1[j]))
                    else:
                        dist.append(np.linalg.norm(np.array(s2[i])-np.array(s1[j])))
        else:
            for i in range(m):
                for j in range(n):
                    if (len(s1[i])>=len(s2[j])) and str(type(s1[i][0])!='<class \'list\'>'):
                        dist.append(self.clusterdist(s1[i],s2[j]))
                    else:
                        dist.append(np.linalg.norm(np.array(s1[i])-np.array(s2[j])))
        return min(dist)
    
    def clusterdist(self,cl,sample):
        if sample[0]!='<class \'list\'>':
            sample = [sample]
        dist   = []
        for i in range(len(cl)):
            for j in range(len(sample)):
                dist.append(np.linalg.norm(np.array(cl[i])-np.array(sample[j])))
        return min(dist)
    
      
    def cal_distance(self,samples):
        Distance_mat = np.zeros((len(samples),len(samples)))
        for i in range(Distance_mat.shape[0]):
            for j in range(Distance_mat.shape[0]):
                if i!=j:
                    Distance_mat[i,j] = float(self.distance(samples[i],samples[j]))
                else:
                    Distance_mat[i,j] = 10**4
        return Distance_mat
    
    
    def distance(self,sample1,sample2):
        dist = []
        for i in range(len(sample1)):
            for j in range(len(sample2)):
                try:
                    dist.append(np.linalg.norm(np.array(sample1[i])-np.array(sample2[j])))
                except:
                    dist.append(self.sampledist(sample1[i],sample2[j]))
        return min(dist)
    


# In[44]:


progression = [[i] for i in range(X.shape[0])]
samples     = [[list(X[i])] for i in range(X.shape[0])]
n = len(samples)
dist  = Distance()

while n>1:
    Distance_mat = dist.cal_distance(samples)
    sample = np.where(Distance_mat==Distance_mat.min())[0]
    to_add      = samples.pop(sample[1])
    samples[sample[0]].append(to_add)
    progression[sample[0]].append(progression[sample[1]])
    progression[sample[0]] = [progression[sample[0]]]
    v = progression.pop(sample[1])
    n = len(samples)
    
#here we are trying to find max distance in matrix
while n>1:
    Distance_mat      = dist.cal_distance(samples)
    sample = np.where(Distance_mat==Distance_mat.max())[0]
    to_add      = samples.pop(sample[1])
    samples[sample[0]].append(to_add)
    progression[sample[0]].append(progression[sample[1]])
    progression[sample[0]] = [progression[sample[0]]]
    v = progression.pop(sample[1])
    n = len(samples)
    
#here we are trying to find average distance in matrix
while n>1:
    Distance_mat      = dist.cal_distance(samples)
    sample = np.where(Distance_mat==Distance_mat.mean())[0]
    to_add      = samples.pop(sample[1])
    samples[sample[0]].append(to_add)
    progression[sample[0]].append(progression[sample[1]])
    progression[sample[0]] = [progression[sample[0]]]
    v = progression.pop(sample[1])
    n = len(samples)

